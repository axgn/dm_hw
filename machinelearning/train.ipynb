{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a005d951",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "# 相关训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e13c6",
   "metadata": {},
   "source": [
    "1. 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c08a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    \"../datasets/ml-25m/ratings.csv\"\n",
    ")\n",
    "movies = pd.read_csv(\n",
    "    \"../datasets/ml-25m/movies.csv\",\n",
    ")\n",
    "df = pd.merge(ratings, movies[['movieId', 'title']], on='movieId')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ce8f6",
   "metadata": {},
   "source": [
    "2. 构建矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889890f",
   "metadata": {},
   "source": [
    "这里由于矩阵如果直接使用非常pivot_table去构建一个评分矩阵会爆内存，所以这里对索引进行编码后，使用scipy的csr_matrix构建矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcb30a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162541, 59047)\n",
      "25000095\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# 编码（避免巨大稀疏索引）\n",
    "user_codes = df['userId'].astype('category').cat.codes\n",
    "movie_codes = df['movieId'].astype('category').cat.codes\n",
    "\n",
    "ratings_sparse = csr_matrix(\n",
    "    (df['rating'], (user_codes, movie_codes))\n",
    ")\n",
    "\n",
    "print(ratings_sparse.shape)\n",
    "print(ratings_sparse.nnz)   # 非零元素数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a388b0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m         topk_sim[i] = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(topk_idx, sim[topk_idx]))\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m topk_sim\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m topk_sim_dict = \u001b[43mtopk_user_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtopk_user_similarity\u001b[39m\u001b[34m(ratings_sparse, k)\u001b[39m\n\u001b[32m      6\u001b[39m topk_sim = {}\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_users):\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# 计算第 i 个用户与所有用户的余弦相似度\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     sim = \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings_sparse\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings_sparse\u001b[49m\u001b[43m)\u001b[49m.flatten()\n\u001b[32m     11\u001b[39m     sim[i] = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# 排除自己\u001b[39;00m\n\u001b[32m     12\u001b[39m     topk_idx = np.argpartition(-sim, k)[:k]  \u001b[38;5;66;03m# 取前 k\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Myfiles/code/homework/dm_hw2/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Myfiles/code/homework/dm_hw2/.venv/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:1734\u001b[39m, in \u001b[36mcosine_similarity\u001b[39m\u001b[34m(X, Y, dense_output)\u001b[39m\n\u001b[32m   1732\u001b[39m     Y_normalized = X_normalized\n\u001b[32m   1733\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1734\u001b[39m     Y_normalized = \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1736\u001b[39m K = safe_sparse_dot(X_normalized, Y_normalized.T, dense_output=dense_output)\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Myfiles/code/homework/dm_hw2/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Myfiles/code/homework/dm_hw2/.venv/lib/python3.13/site-packages/sklearn/preprocessing/_data.py:2000\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(X, norm, axis, copy, return_norm)\u001b[39m\n\u001b[32m   1998\u001b[39m     inplace_csr_row_normalize_l1(X)\n\u001b[32m   1999\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m norm == \u001b[33m\"\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2000\u001b[39m     \u001b[43minplace_csr_row_normalize_l2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2001\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m norm == \u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2002\u001b[39m     mins, maxes = min_max_axis(X, \u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def topk_user_similarity(ratings_sparse, k=50):\n",
    "    n_users = ratings_sparse.shape[0]\n",
    "    topk_sim = {}\n",
    "\n",
    "    for i in range(n_users):\n",
    "        # 计算第 i 个用户与所有用户的余弦相似度\n",
    "        sim = cosine_similarity(ratings_sparse[i], ratings_sparse).flatten()\n",
    "        sim[i] = 0  # 排除自己\n",
    "        topk_idx = np.argpartition(-sim, k)[:k]  # 取前 k\n",
    "        topk_sim[i] = list(zip(topk_idx, sim[topk_idx]))\n",
    "\n",
    "    return topk_sim\n",
    "\n",
    "topk_sim_dict = topk_user_similarity(ratings_sparse, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a59d153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import numpy as np\n",
    "\n",
    "# # 用 0 替换 NaN 计算相似度\n",
    "# user_matrix = rating_matrix.fillna(0)\n",
    "\n",
    "# # 计算用户-用户相似度矩阵\n",
    "# user_similarity = cosine_similarity(user_matrix)\n",
    "# user_similarity = pd.DataFrame(user_similarity, index=rating_matrix.index, columns=rating_matrix.index)\n",
    "\n",
    "# user_similarity.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3a1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_user = 1\n",
    "# top_users = user_similarity[target_user].sort_values(ascending=False)[1:6]\n",
    "# print(top_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "916dd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 权重相似度的加权平均\n",
    "# def predict_ratings(user_id, rating_matrix, user_similarity):\n",
    "#     sim_scores = user_similarity[user_id]\n",
    "#     user_ratings = rating_matrix.loc[user_id]\n",
    "    \n",
    "#     # 未评分的电影\n",
    "#     unrated_movies = user_ratings[user_ratings.isna()].index\n",
    "    \n",
    "#     pred_ratings = {}\n",
    "#     for movie in unrated_movies:\n",
    "#         # 取其他用户对该电影的评分\n",
    "#         other_ratings = rating_matrix[movie]\n",
    "        \n",
    "#         # 计算加权平均（忽略NaN）\n",
    "#         mask = ~other_ratings.isna()\n",
    "#         if mask.sum() == 0:\n",
    "#             continue\n",
    "#         pred = np.dot(sim_scores[mask], other_ratings[mask]) / sim_scores[mask].sum()\n",
    "#         pred_ratings[movie] = pred\n",
    "#     return pd.Series(pred_ratings).sort_values(ascending=False)\n",
    "\n",
    "# # 给用户1推荐电影\n",
    "# predicted_ratings = predict_ratings(4, rating_matrix, user_similarity)\n",
    "# predicted_ratings.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm-hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
