{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a005d951",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "# 相关训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e13c6",
   "metadata": {},
   "source": [
    "1. 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c08a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    \"../datasets/ml-25m/ratings.csv\"\n",
    ")\n",
    "movies = pd.read_csv(\n",
    "    \"../datasets/ml-25m/movies.csv\",\n",
    ")\n",
    "df = pd.merge(ratings, movies[['movieId', 'title']], on='movieId')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e300864",
   "metadata": {},
   "source": [
    "2. 使用留出法制作训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1c1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 20062533 test: 4937562\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def split_low_memory(df, test_ratio=0.2, min_items=5, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    test_indices = []\n",
    "\n",
    "    for uid, group in df.groupby(\"userId\"):\n",
    "        if len(group) < min_items:\n",
    "            continue\n",
    "\n",
    "        test_size = max(1, int(len(group) * test_ratio))\n",
    "        chosen = rng.choice(group.index, size=test_size, replace=False)\n",
    "        test_indices.extend(chosen)\n",
    "\n",
    "    test_indices = set(test_indices)\n",
    "    mask = df.index.isin(test_indices)\n",
    "    return df[~mask], df[mask]\n",
    "\n",
    "\n",
    "train_df, test_df = split_low_memory(df)\n",
    "print(\"train:\", len(train_df), \"test:\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530cd756",
   "metadata": {},
   "source": [
    "回收df，减少内存占用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c50dba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e102d705",
   "metadata": {},
   "source": [
    "3. 建立训练集的稀疏矩阵，同时将测试集转换为（用户，电影，评分）元组的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5dd569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sparse shape: (162541, 56654)\n",
      "test tuples: 4934713\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def build_train_test(train_df, test_df):\n",
    "    # category 创建映射\n",
    "    user_cat = train_df[\"userId\"].astype(\"category\")\n",
    "    movie_cat = train_df[\"movieId\"].astype(\"category\")\n",
    "\n",
    "    u_train = user_cat.cat.codes.values\n",
    "    m_train = movie_cat.cat.codes.values\n",
    "    r_train = train_df[\"rating\"].values\n",
    "\n",
    "    user_categories = user_cat.cat.categories\n",
    "    movie_categories = movie_cat.cat.categories\n",
    "\n",
    "    # 测试集映射到训练集空间\n",
    "    u_test = pd.Categorical(test_df[\"userId\"], user_categories).codes\n",
    "    m_test = pd.Categorical(test_df[\"movieId\"], movie_categories).codes\n",
    "    r_test = test_df[\"rating\"].values\n",
    "\n",
    "    # 过滤掉 -1（训练集没出现）\n",
    "    mask = (u_test != -1) & (m_test != -1)\n",
    "    test_tuples = list(zip(u_test[mask], m_test[mask], r_test[mask]))\n",
    "\n",
    "    mat = csr_matrix((r_train, (u_train, m_train)), shape=(len(user_categories), len(movie_categories)))\n",
    "\n",
    "    return mat, test_tuples\n",
    "train_sparse, test_tuples = build_train_test(train_df, test_df)\n",
    "print(\"train sparse shape:\", train_sparse.shape)\n",
    "print(\"test tuples:\", len(test_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9deb123",
   "metadata": {},
   "source": [
    "4. 将训练集进行svd分解防止在后续训练过程中爆内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce0b9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train user vectors shape: (162541, 128)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "def build_user_vectors(train_mat,dim=128):\n",
    "    # 每个用户是一行\n",
    "    # 我们需要 dense 向量给 hnswlib，用 float32\n",
    "    svd = TruncatedSVD(n_components=dim, random_state=42)\n",
    "    X = svd.fit_transform(train_mat.astype(\"float32\"))\n",
    "    X = normalize(X, axis=1)\n",
    "    return X\n",
    "\n",
    "train_user_vectors = build_user_vectors(train_sparse)\n",
    "print(\"train user vectors shape:\", train_user_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1089dd2",
   "metadata": {},
   "source": [
    "5. 建立hnsw进行查询时需要的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c8d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN index built.\n"
     ]
    }
   ],
   "source": [
    "import hnswlib\n",
    "\n",
    "\n",
    "def build_ann_index(X, ef=200, M=32):\n",
    "    dim = X.shape[1]\n",
    "    num_users = X.shape[0]\n",
    "    index = hnswlib.Index(space=\"cosine\", dim=dim)\n",
    "    index.init_index(max_elements=num_users, ef_construction=ef, M=M)\n",
    "    index.add_items(X)\n",
    "    index.set_ef(ef)\n",
    "    return index\n",
    "\n",
    "ann_index = build_ann_index(train_user_vectors)\n",
    "print(\"ANN index built.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dd76a7",
   "metadata": {},
   "source": [
    "6. 将每个用户的前50个最相似用户及相应的余弦距离进行缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ac963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors cache shape: (162541, 50)\n",
      "Sims cache shape: (162541, 50)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cache_user_neighbors(index, user_emb, k):\n",
    "    num_users = user_emb.shape[0]\n",
    "    neighbors_cache = {}\n",
    "    sims_cache = {}\n",
    "\n",
    "    for u in range(num_users):\n",
    "        neigh, sims = index.knn_query(user_emb[u], k=k + 1)\n",
    "        neigh = neigh[0]\n",
    "        sims = sims[0]\n",
    "\n",
    "        mask = neigh != u\n",
    "        neighbors_cache[u] = neigh[mask]\n",
    "        sims_cache[u] = sims[mask]\n",
    "\n",
    "    return neighbors_cache, sims_cache\n",
    "\n",
    "neighbors_cache, sims_cache = cache_user_neighbors(ann_index, train_user_vectors, k=50)\n",
    "print(\"Neighbors cache shape:\", len(neighbors_cache))\n",
    "print(\"Sims cache shape:\", len(sims_cache))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f529633",
   "metadata": {},
   "source": [
    "7. 根据前面得到的缓存计算每个用户对电影列表内电影的评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ffe0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_movies(train_mat, user, movie_list, neighbors_cache, sims_cache):\n",
    "    neigh = neighbors_cache[user]\n",
    "    sims = sims_cache[user] \n",
    "\n",
    "    neigh_ratings = train_mat[neigh].toarray()\n",
    "    sims = sims.reshape(-1, 1)\n",
    "\n",
    "    weighted_sum = (neigh_ratings * sims).sum(axis=0)\n",
    "    weight_norm = sims.sum()\n",
    "\n",
    "    user_pred = weighted_sum / (weight_norm + 1e-8)\n",
    "\n",
    "    return user_pred[movie_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb4622",
   "metadata": {},
   "source": [
    "8. 计算rmse(均方根误差)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8fea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 2.607566735338708\n"
     ]
    }
   ],
   "source": [
    "def rmse_user_batch(train_mat, test_tuples, neighbors_cache, sims_cache):\n",
    "    # 把 test_tuples 按用户聚合\n",
    "    user_to_movies = {}\n",
    "    for u, m, r in test_tuples:\n",
    "        user_to_movies.setdefault(u, []).append((m, r))\n",
    "\n",
    "    se = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for u, pairs in user_to_movies.items():\n",
    "        movies = [m for m, _ in pairs]\n",
    "        reals = np.array([r for _, r in pairs])\n",
    "\n",
    "        preds = predict_user_movies(train_mat, u, movies, neighbors_cache, sims_cache)\n",
    "\n",
    "        se += ((preds - reals) ** 2).sum()\n",
    "        n += len(pairs)\n",
    "\n",
    "    return (se / n) ** 0.5\n",
    "\n",
    "rmse = rmse_user_batch(train_sparse, test_tuples, neighbors_cache, sims_cache)\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd9702d",
   "metadata": {},
   "source": [
    "9. 计算用户对所有电影的评分，并得到其中的topk个电影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e264a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-K recommendations for user 0: [4867 7236  292 5904 6588 4040 2600  302 7198 4742]\n"
     ]
    }
   ],
   "source": [
    "def predict_user_all_movies(train_mat, user, neighbors_cache, sims_cache):\n",
    "    neigh = neighbors_cache[user]\n",
    "    sims = sims_cache[user].reshape(-1, 1)\n",
    "\n",
    "    neigh_ratings = train_mat[neigh].toarray()  # K × M\n",
    "\n",
    "    weighted_sum = (neigh_ratings * sims).sum(axis=0)\n",
    "    denom = sims.sum() + 1e-8\n",
    "\n",
    "    preds = weighted_sum / denom  # shape = (M,)\n",
    "    return preds\n",
    "\n",
    "def recommend_topk(train_mat, user, Krec, watched_set, neighbors_cache, sims_cache):\n",
    "    preds = predict_user_all_movies(train_mat, user, neighbors_cache, sims_cache)\n",
    "\n",
    "    # 去掉用户训练集中已经看过的电影\n",
    "    preds[list(watched_set)] = -1e9\n",
    "\n",
    "    # 选取评分最高的 Krec\n",
    "    topk = np.argpartition(preds, -Krec)[-Krec:]\n",
    "    topk = topk[np.argsort(-preds[topk])]\n",
    "\n",
    "    return topk\n",
    "\n",
    "topk = recommend_topk(train_sparse, user=0, Krec=10, watched_set={1,2,3}, neighbors_cache=neighbors_cache, sims_cache=sims_cache)\n",
    "print(\"Top-K recommendations for user 0:\", topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30859b",
   "metadata": {},
   "source": [
    "10. 进行召回率的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-K Recall@50: 0.5043139056021698\n"
     ]
    }
   ],
   "source": [
    "def recall_at_k(train_mat, test_tuples, neighbors_cache, sims_cache, Krec=50, like_threshold=4.0):\n",
    "    # 组织测试集：user → [(movie, rating)]\n",
    "    test_map = {}\n",
    "    for u, m, r in test_tuples:\n",
    "        test_map.setdefault(u, []).append((m, r))\n",
    "\n",
    "    # 训练集已看电影（避免推荐重复）\n",
    "    watched = {u: set(train_mat[u].indices) for u in range(train_mat.shape[0])}\n",
    "\n",
    "    sum_recall = 0\n",
    "    cnt_user = 0\n",
    "\n",
    "    for u, pairs in test_map.items():\n",
    "        # 用户在测试集中真正喜欢的电影\n",
    "        liked = [m for m, r in pairs if r >= like_threshold]\n",
    "        if not liked:\n",
    "            continue  # 没有喜欢电影就跳过，不影响指标\n",
    "\n",
    "        rec_list = recommend_topk(train_mat, u, Krec, watched[u], neighbors_cache, sims_cache)\n",
    "\n",
    "        hit = sum(1 for m in liked if m in rec_list)\n",
    "        recall = hit / len(liked)\n",
    "\n",
    "        sum_recall += recall\n",
    "        cnt_user += 1\n",
    "\n",
    "    return sum_recall / cnt_user\n",
    "\n",
    "topk_recall = recall_at_k(train_sparse, test_tuples, neighbors_cache, sims_cache, Krec=50, like_threshold=4.0)\n",
    "print(\"Top-K Recall@50:\", topk_recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm-hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
